{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB: Feature Selection\n",
    "\n",
    "En este lab vamos a explorar selección de características. Seguiremos trabajando sobre el dataset de Titanic.\n",
    "\n",
    "Ante que nada, carguemos\n",
    "\n",
    "- Paquetes estándar\n",
    "- El dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descartemos las variables que no vamos a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[[u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare', u'Embarked']]\n",
    "y = df[u'Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequeemos la existencia de valores perdidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in X.columns.values:\n",
    "    print i,\":\", sum(X[i].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = X['Embarked'].fillna('Q')\n",
    "X.loc[:,'Embarked'] = s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora generemos un pipeline que realice las siguientes tareas de preprocesamiento de la información:\n",
    "\n",
    "- Normalize las variables numéricas\n",
    "- Genere dummies de las variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder,Imputer, OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from IPython.core.debugger import Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DataFrameColumnExtracter(TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns, y = None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        col_list = []\n",
    "        for c in self.columns:\n",
    "            col_list.append(c)\n",
    "        return (X[col_list])\n",
    "        #return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndebug_here = Tracer()\n",
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('cont', Pipeline([\n",
    "            ('extract', DataFrameColumnExtracter([u'Age',u'Fare',u'Parch',u'SibSp'])),\n",
    "            ('impute', Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "            ('scale', StandardScaler())\n",
    "        ])),\n",
    "        ('cat', Pipeline([\n",
    "            ('extract', DataFrameColumnExtracter([u'Pclass', u'Sex',u'Embarked'])),\n",
    "            ('categ', LabelEncoder()),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='error', n_values='auto', sparse=False)),\n",
    "        ])),\n",
    "    ])\n",
    ")])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1 Nombres de columnas\n",
    "\n",
    "Parece que se han perdido algunos nombres de columna! Vamos a agegarlas manualmente:\n",
    "- pipe_edad => 'scaled_age'\n",
    "- pipe_puerto => 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'\n",
    "- pipe_sexo => 'male'\n",
    "- pipe_tarifa => 'scaled_fare'\n",
    "\n",
    "Vamos a necesitar:\n",
    "\n",
    "1. Crear un nuevo dataframe Pandas llamado \"Xt\" con los nombres de columna apropiados y llenaron con los datos de \"X_transf\".\n",
    "2. Dado que el Pipeline descarta las columnas \"SibSp\" y \"Parch\", agreguémoslos como están en el nuevo dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_cols = ['scaled_age', 'Pclass_1', 'Pclass_2', 'Pclass_3',\n",
    "            'Embarked_C', 'Embarked_Q', 'Embarked_S',\n",
    "            'male', 'scaled_fare']\n",
    "\n",
    "Xt = pd.DataFrame(X_transf, columns=new_cols)\n",
    "Xt = pd.concat([Xt, X[[u'SibSp', u'Parch']]], axis = 1)\n",
    "Xt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature selection\n",
    "\n",
    "Utilicemos el método \"SelectKBest\" de scikit learn a ver cuáles son las top 5 características.\n",
    "\n",
    "Cuáles son?\n",
    "\n",
    "\n",
    "Guardémoslas en una variable llamada \"kbest_columns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selector = SelectKBest(f_classif, k=5)\n",
    "selected_data = selector.fit_transform(Xt, y)\n",
    "kbest_columns = Xt.columns[selector.get_support()]\n",
    "Xtbest = pd.DataFrame(selected_data, columns=kbest_columns)\n",
    "Xtbest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Eliminación recursiva de características\n",
    "\n",
    "En Scikit Learn también vamos a encontrar una clase para realizar una eliminación recursiva de características. La misma se llama \"RFECV\". Usémosla en combinación de un modelo de regresión logística para ver qué características serán conservadas con este método.\n",
    "\n",
    "Guardémoslas en una variable llamada \"rfecv_columns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator = LogisticRegression()\n",
    "selector = RFECV(estimator, step=1, cv=5)\n",
    "selector = selector.fit(Xt, y)\n",
    "rfecv_columns = Xt.columns[selector.support_]\n",
    "rfecv_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Coeficientes de Regresión Logística\n",
    "\n",
    "Veamos si los coeficientes de una RL se condicen.\n",
    "\n",
    "- Creá un modelo de regresión logística\n",
    "- Ejecutá un grid search sobre los parámetros \"penalty type\" y \"C strength\" para encontrar la mejor combinación\n",
    "- Ordená los coeficientes obtenidos por valor absoluto (módulo). El top 5 coincide con los de arriba? Por qué/Por qué no? (Pista: Están todos los valores en la misma escala?)\n",
    "\n",
    "Guardemos las que querramos mantener en una variable llamada \"lr_columns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = GridSearchCV(LogisticRegression(), {'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "                                            'penalty': ['l1', 'l2']})\n",
    "model.fit(Xt, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coeffs = pd.DataFrame(model.best_estimator_.coef_, columns = Xt.columns)\n",
    "coeffs_t = coeffs.transpose()\n",
    "coeffs_t.columns = ['Surv coeff']\n",
    "coeffs_t.abs().sort_values('Surv coeff', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep the ones with coeff above 0.3\n",
    "lr_columns = coeffs.columns[(coeffs.abs() > 0.3).values[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparar sets de características\n",
    "\n",
    "Usá el \"best estimator\" del punto anterior sobre los sets de características obtenidos:\n",
    "\n",
    "- \"kbest_columns\"\n",
    "- \"rfecv_columns\"\n",
    "- \"lr_columns\"\n",
    "- \"all_columns\"\n",
    "\n",
    "Usá validación cruzada (cross_val_score) para evaluar los modelos \n",
    "Preguntas:\n",
    "\n",
    "- Cuál obtuvo mejores resultados?\n",
    "- Hay diferencias signigicativas?\n",
    "- Cuál es la mejor opción? Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "def score(X):\n",
    "    scores = cross_val_score(model.best_estimator_, X, y)\n",
    "    return scores.mean(), scores.std()\n",
    "\n",
    "all_scores = [\n",
    "    score(Xt[kbest_columns]),\n",
    "    score(Xt[rfecv_columns]),\n",
    "    score(Xt[lr_columns]),\n",
    "    score(Xt)]\n",
    "\n",
    "pd.DataFrame(all_scores, columns=['mean score', 'std score'], index = ['kbest', 'rfecv', 'lr', 'all'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Creá un grágico de barras para mostrar los coeficientes de la regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coeffs_t.sort_values('Surv coeff').plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
